{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from MNISTConvNet import MNISTConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skopt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                        name='learning_rate')\n",
    "\n",
    "dim_num_conv_layers = Integer(low=1, high=3, name='num_conv_layers')\n",
    "\n",
    "dim_num_fc_units = Integer(low=5, high=512, name='num_fc_units')\n",
    "\n",
    "dim_dropout_rate = Real(low=1e-5, high=1e-2, prior='log-uniform',\n",
    "                        name='dropout_rate')\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_conv_layers,\n",
    "              dim_num_fc_units,\n",
    "              dim_dropout_rate]\n",
    "\n",
    "default_parameters = [1e-5, 1, 16, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "                        root='./data/MNIST',\n",
    "                        train=True,           #Training Set of 60,000 images\n",
    "                        download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(0, 1)\n",
    "                        ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "                        root='./data/MNIST',\n",
    "                        train=False,          #Test Set of 10,000 images\n",
    "                        download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(0, 1)\n",
    "                        ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=100\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, lr, num_epoch, train_loader, test_loader):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "            \n",
    "            preds = model(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        print('epoch:', epoch, 'total_correct:', total_correct, 'loss:', total_loss)\n",
    "\n",
    "    print('Train Accuracy:', total_correct/len(train_set))\n",
    "\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        test_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print('Test Accuracy:', test_correct/len(test_set))\n",
    "    \n",
    "    return test_correct/len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "best_model_path = './best_model.pth'\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_conv_layers,\n",
    "            num_fc_units, dropout_rate):\n",
    "\n",
    "    print('\\n\\nlearning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_conv_layers:', num_conv_layers)\n",
    "    print('num_fc_units:', num_fc_units)\n",
    "    print('dropout_rate:', dropout_rate)\n",
    "    \n",
    "    model = MNISTConvNet(num_conv_layers=num_conv_layers,\n",
    "                         num_fc_units=num_fc_units,\n",
    "                         dropout_rate=dropout_rate)\n",
    "\n",
    "    accuracy = train(model, learning_rate, 1, train_loader, test_loader)\n",
    "\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "    global best_accuracy\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    del model\n",
    "\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "learning rate: 1.0e-05\n",
      "num_conv_layers: 1\n",
      "num_fc_units: 16\n",
      "dropout_rate: 0.0001\n",
      "epoch: 0 total_correct: 26059 loss: 12387.331575155258\n",
      "Train Accuracy: 0.4343166666666667\n",
      "Test Accuracy: 0.5897\n",
      "Accuracy: 0.5897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.5897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "learning rate: 1.0e-05\n",
      "num_conv_layers: 1\n",
      "num_fc_units: 16\n",
      "dropout_rate: 0.0001\n",
      "epoch: 0 total_correct: 15729 loss: 13067.952606797218\n",
      "Train Accuracy: 0.26215\n",
      "Test Accuracy: 0.4374\n",
      "Accuracy: 0.4374\n",
      "\n",
      "\n",
      "learning rate: 7.6e-06\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 242\n",
      "dropout_rate: 0.0010504029270412094\n",
      "epoch: 0 total_correct: 24842 loss: 13070.13498198986\n",
      "Train Accuracy: 0.4140333333333333\n",
      "Test Accuracy: 0.6666\n",
      "Accuracy: 0.6666\n",
      "\n",
      "\n",
      "learning rate: 4.4e-04\n",
      "num_conv_layers: 3\n",
      "num_fc_units: 260\n",
      "dropout_rate: 0.0016246152039815\n",
      "epoch: 0 total_correct: 45744 loss: 4319.715989653021\n",
      "Train Accuracy: 0.7624\n",
      "Test Accuracy: 0.8577\n",
      "Accuracy: 0.8577\n",
      "\n",
      "\n",
      "learning rate: 1.2e-06\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 384\n",
      "dropout_rate: 0.005346756084445474\n",
      "epoch: 0 total_correct: 7529 loss: 13711.089743852615\n",
      "Train Accuracy: 0.12548333333333334\n",
      "Test Accuracy: 0.2522\n",
      "Accuracy: 0.2522\n",
      "\n",
      "\n",
      "learning rate: 1.6e-04\n",
      "num_conv_layers: 3\n",
      "num_fc_units: 140\n",
      "dropout_rate: 0.003035356507066432\n",
      "epoch: 0 total_correct: 36893 loss: 7065.959662541747\n",
      "Train Accuracy: 0.6148833333333333\n",
      "Test Accuracy: 0.7614\n",
      "Accuracy: 0.7614\n",
      "\n",
      "\n",
      "learning rate: 1.4e-06\n",
      "num_conv_layers: 1\n",
      "num_fc_units: 59\n",
      "dropout_rate: 6.311668307810025e-05\n",
      "epoch: 0 total_correct: 6396 loss: 13740.879770755768\n",
      "Train Accuracy: 0.1066\n",
      "Test Accuracy: 0.183\n",
      "Accuracy: 0.183\n",
      "\n",
      "\n",
      "learning rate: 4.7e-06\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 132\n",
      "dropout_rate: 0.0012429872607034348\n",
      "epoch: 0 total_correct: 8273 loss: 13779.669374227524\n",
      "Train Accuracy: 0.13788333333333333\n",
      "Test Accuracy: 0.2341\n",
      "Accuracy: 0.2341\n",
      "\n",
      "\n",
      "learning rate: 2.6e-03\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 56\n",
      "dropout_rate: 0.007476329578576925\n",
      "epoch: 0 total_correct: 56231 loss: 1230.8544045827366\n",
      "Train Accuracy: 0.9371833333333334\n",
      "Test Accuracy: 0.9485\n",
      "Accuracy: 0.9485\n",
      "\n",
      "\n",
      "learning rate: 1.8e-03\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 393\n",
      "dropout_rate: 2.1738843582354433e-05\n",
      "epoch: 0 total_correct: 56151 loss: 1237.3182572962978\n",
      "Train Accuracy: 0.93585\n",
      "Test Accuracy: 0.9646\n",
      "Accuracy: 0.9646\n",
      "\n",
      "\n",
      "learning rate: 3.7e-06\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 119\n",
      "dropout_rate: 3.228465519472421e-05\n",
      "epoch: 0 total_correct: 11151 loss: 13643.412776470184\n",
      "Train Accuracy: 0.18585\n",
      "Test Accuracy: 0.2626\n",
      "Accuracy: 0.2626\n",
      "\n",
      "\n",
      "learning rate: 2.4e-04\n",
      "num_conv_layers: 2\n",
      "num_fc_units: 348\n",
      "dropout_rate: 0.0022895272112423352\n",
      "epoch: 0 total_correct: 53436 loss: 2316.87413629645\n",
      "Train Accuracy: 0.8906\n",
      "Test Accuracy: 0.9425\n",
      "Accuracy: 0.9425\n",
      "\n",
      "\n",
      "learning rate: 1.0e-02\n",
      "num_conv_layers: 1\n",
      "num_fc_units: 512\n",
      "dropout_rate: 0.01\n",
      "epoch: 0 total_correct: 56448 loss: 1215.564034439112\n",
      "Train Accuracy: 0.9408\n",
      "Test Accuracy: 0.9523\n",
      "Accuracy: 0.9523\n"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI',\n",
    "                            n_calls=12,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nas_wot import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTConvNet(num_conv_layers=2,\n",
    "                    num_fc_units=393,\n",
    "                    dropout_rate=2.1738843582354433e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTConvNet(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout): Dropout(p=2.1738843582354433e-05, inplace=False)\n",
       "  (fc1): Linear(in_features=125, out_features=393, bias=True)\n",
       "  (fc2): Linear(in_features=393, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTConvNet(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout): Dropout(p=2.1738843582354433e-05, inplace=False)\n",
       "  (fc1): Linear(in_features=125, out_features=393, bias=True)\n",
       "  (fc2): Linear(in_features=393, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-188.19160651956506"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(model, train_loader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([3, 1, 3, 3])\n",
      "conv1.bias \t torch.Size([3])\n",
      "conv2.weight \t torch.Size([5, 3, 3, 3])\n",
      "conv2.bias \t torch.Size([5])\n",
      "fc1.weight \t torch.Size([393, 125])\n",
      "fc1.bias \t torch.Size([393])\n",
      "fc2.weight \t torch.Size([10, 393])\n",
      "fc2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-0.0334,  0.2540,  0.2722],\n",
       "                        [-0.1481,  0.1374,  0.2096],\n",
       "                        [-0.0028,  0.0987,  0.1333]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2304,  0.0182,  0.0352],\n",
       "                        [-0.0602, -0.1293,  0.2283],\n",
       "                        [ 0.2955,  0.1718,  0.0486]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1488,  0.0918, -0.1624],\n",
       "                        [-0.1039,  0.0403,  0.1150],\n",
       "                        [-0.2176, -0.1634, -0.2305]]]])),\n",
       "             ('conv1.bias', tensor([ 0.3181, -0.3295, -0.2656])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 0.0187, -0.0344,  0.0789],\n",
       "                        [-0.0025, -0.0050, -0.1529],\n",
       "                        [ 0.1063, -0.1450,  0.1359]],\n",
       "              \n",
       "                       [[ 0.0309, -0.1372, -0.0374],\n",
       "                        [ 0.1320,  0.0930,  0.0463],\n",
       "                        [ 0.0705, -0.1357,  0.0811]],\n",
       "              \n",
       "                       [[ 0.0776,  0.1917,  0.0843],\n",
       "                        [-0.1473, -0.1066,  0.1051],\n",
       "                        [-0.1105, -0.0830, -0.0231]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0003,  0.0257, -0.0040],\n",
       "                        [-0.1128,  0.0636,  0.0861],\n",
       "                        [-0.0696,  0.1668,  0.0281]],\n",
       "              \n",
       "                       [[-0.1675, -0.1297, -0.0361],\n",
       "                        [ 0.1188,  0.1671, -0.0264],\n",
       "                        [ 0.0936, -0.0712,  0.1492]],\n",
       "              \n",
       "                       [[-0.0963,  0.1618,  0.0204],\n",
       "                        [-0.1423,  0.0828,  0.1560],\n",
       "                        [ 0.1361,  0.0662,  0.1690]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1249, -0.1168, -0.0960],\n",
       "                        [-0.1472, -0.1518,  0.0453],\n",
       "                        [ 0.0015, -0.0494,  0.0986]],\n",
       "              \n",
       "                       [[-0.1472,  0.0226,  0.0290],\n",
       "                        [-0.0342,  0.0974, -0.1606],\n",
       "                        [-0.1006,  0.0332,  0.1498]],\n",
       "              \n",
       "                       [[ 0.1025,  0.0603, -0.0256],\n",
       "                        [ 0.0965,  0.1199, -0.0428],\n",
       "                        [-0.0733, -0.1415,  0.0356]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1725, -0.1404, -0.1522],\n",
       "                        [-0.1698, -0.1673,  0.0886],\n",
       "                        [ 0.0780,  0.0566, -0.0939]],\n",
       "              \n",
       "                       [[-0.0647,  0.1720,  0.1272],\n",
       "                        [ 0.1642,  0.0990, -0.1654],\n",
       "                        [-0.1773, -0.1800,  0.0809]],\n",
       "              \n",
       "                       [[ 0.1137,  0.0790, -0.0787],\n",
       "                        [-0.1809, -0.1115, -0.0010],\n",
       "                        [ 0.1790,  0.0311,  0.1730]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1558,  0.1095, -0.0694],\n",
       "                        [ 0.0950, -0.1723, -0.0938],\n",
       "                        [ 0.1262, -0.1608,  0.0503]],\n",
       "              \n",
       "                       [[-0.0891, -0.1506, -0.0226],\n",
       "                        [ 0.0269, -0.0862, -0.1794],\n",
       "                        [ 0.1465, -0.1512, -0.1819]],\n",
       "              \n",
       "                       [[ 0.0596, -0.1789, -0.1101],\n",
       "                        [ 0.1261,  0.0179,  0.1751],\n",
       "                        [-0.1893,  0.1135,  0.0372]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.1222, -0.0427,  0.1562, -0.0561, -0.0223])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0399,  0.0089,  0.0713,  ...,  0.0257,  0.0866,  0.0134],\n",
       "                      [ 0.0764,  0.0611,  0.0729,  ..., -0.0435,  0.0630,  0.0354],\n",
       "                      [ 0.0003, -0.0572,  0.0488,  ..., -0.0331, -0.0550, -0.0778],\n",
       "                      ...,\n",
       "                      [ 0.0706, -0.0718, -0.0449,  ..., -0.0609,  0.0371,  0.0836],\n",
       "                      [ 0.0525,  0.0129, -0.0659,  ..., -0.0264,  0.0133,  0.0093],\n",
       "                      [ 0.0762,  0.0375,  0.0041,  ..., -0.0779,  0.0408,  0.0367]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 1.2106e-02, -9.3960e-03, -3.2995e-02, -5.5060e-02,  6.1012e-02,  7.6094e-02, -7.1998e-02, -6.0250e-02,\n",
       "                       4.8357e-02,  5.3396e-02,  1.9706e-02,  4.0909e-02,  6.5141e-02, -1.6217e-02,  7.1508e-02, -4.0237e-02,\n",
       "                       2.9264e-02, -3.2498e-02,  6.8787e-02, -2.8797e-02, -2.0658e-02,  8.0682e-02, -7.0896e-02, -4.0659e-02,\n",
       "                      -2.9053e-03, -5.6392e-02, -2.7199e-02, -1.9690e-02,  2.6025e-02,  1.3009e-05,  2.9382e-02,  5.4574e-02,\n",
       "                      -6.9351e-02,  2.6873e-02,  4.5354e-02,  5.7556e-02, -8.2175e-02,  2.6898e-02,  8.9228e-02, -7.9680e-02,\n",
       "                      -8.1598e-02,  3.1085e-02,  2.0678e-02, -7.4193e-02,  2.3458e-02,  5.1914e-02, -2.8292e-02, -1.9207e-02,\n",
       "                       1.2081e-02,  6.1091e-02, -4.3525e-02,  3.6651e-03,  2.1037e-02,  2.1467e-02, -3.8548e-02,  8.5247e-02,\n",
       "                      -7.4854e-02,  2.2128e-02,  4.0899e-02, -4.0554e-02, -1.1211e-02, -1.8056e-02, -1.7709e-02, -2.8012e-02,\n",
       "                      -8.2886e-02,  3.9744e-02,  6.3535e-02, -5.6841e-02,  8.1652e-02, -7.8717e-02, -3.9847e-02,  7.9269e-02,\n",
       "                      -1.0111e-02,  2.8830e-02,  2.6960e-02, -2.5012e-02,  5.8482e-02,  2.3518e-02, -2.1332e-02,  2.2830e-02,\n",
       "                      -2.6102e-02, -3.3939e-03, -1.4684e-03, -2.6891e-02, -6.5155e-02, -2.6260e-02,  2.4985e-02, -1.7943e-02,\n",
       "                      -4.9637e-02, -4.6887e-02, -7.2958e-02, -3.8552e-02, -6.2111e-03,  5.9733e-02,  1.8615e-03,  1.4140e-02,\n",
       "                       8.3496e-03, -6.8297e-02,  2.2579e-02, -4.8121e-02, -5.6591e-02,  3.3715e-02,  6.5109e-02,  7.7038e-03,\n",
       "                      -4.3775e-02, -5.6596e-02, -7.2944e-02,  2.3478e-02,  5.0220e-02,  3.2526e-02, -5.7009e-02,  7.5056e-02,\n",
       "                       7.8210e-02,  3.2834e-02, -3.7406e-02,  6.2159e-02, -5.7014e-02,  5.9717e-02,  1.7416e-02,  2.4631e-02,\n",
       "                      -1.6590e-02,  4.6757e-02, -5.9235e-02,  7.6057e-02,  3.2820e-02, -2.9644e-02, -8.5870e-02,  5.2308e-02,\n",
       "                      -4.3584e-02,  6.6285e-02,  4.2099e-02, -5.4533e-02,  3.3222e-02,  4.0641e-02, -4.1607e-02, -7.4378e-02,\n",
       "                       5.2323e-02, -1.8721e-02,  7.1323e-02, -2.9641e-02, -6.1504e-02, -3.3558e-02, -1.0789e-02,  8.3819e-02,\n",
       "                       5.6048e-02,  3.9669e-02,  2.3009e-02, -8.8094e-02,  8.5212e-02,  4.8343e-04,  7.8165e-02, -8.1557e-02,\n",
       "                      -1.8179e-02,  8.5371e-02,  5.1228e-02, -2.0484e-02, -8.0029e-02,  2.3690e-02, -7.0245e-02, -3.2061e-02,\n",
       "                       2.0150e-02, -1.8370e-02, -1.8520e-02,  8.0415e-02, -9.3522e-03, -4.2516e-02, -5.6023e-02, -6.0026e-02,\n",
       "                      -3.6087e-02, -9.2483e-03, -5.9871e-02, -7.2340e-02,  3.4228e-02, -4.3183e-02,  2.5370e-02, -5.8144e-02,\n",
       "                      -7.2026e-02,  2.7655e-02,  2.2602e-02,  8.9277e-02, -1.0635e-02,  7.8596e-02, -8.1573e-03,  6.2473e-02,\n",
       "                      -8.3082e-02, -8.0948e-02,  8.8262e-02,  1.0902e-02,  4.1168e-02,  3.4341e-02, -2.6965e-02,  7.7726e-02,\n",
       "                       6.2822e-02, -3.0545e-02,  4.2098e-02,  3.7030e-02, -8.5922e-02, -1.1711e-02, -1.2641e-02,  3.9363e-02,\n",
       "                      -2.7748e-02, -1.7174e-02,  3.3892e-03, -2.9836e-02,  2.4088e-03,  6.1615e-02, -4.3316e-02, -7.7307e-02,\n",
       "                       1.1650e-02, -3.6911e-02,  7.7732e-02, -2.6331e-02, -8.0479e-02,  4.1639e-02, -5.2880e-02,  5.2902e-02,\n",
       "                       8.8419e-02, -1.5165e-02,  1.5121e-02,  2.9051e-02,  1.7942e-04, -6.2703e-02,  8.7741e-02,  1.9353e-02,\n",
       "                       1.1796e-02,  5.8269e-02,  7.8580e-02,  4.3349e-03,  6.3623e-02, -4.8538e-02, -3.1176e-02, -7.8767e-02,\n",
       "                       4.0310e-02,  1.5596e-02, -8.7366e-02,  5.2936e-02, -3.6092e-02, -4.7598e-02,  8.5835e-02, -4.1103e-03,\n",
       "                      -7.0669e-02,  7.0338e-02, -2.8841e-02,  4.6844e-02, -2.6747e-02, -6.7348e-02,  5.8394e-03,  4.1300e-03,\n",
       "                       8.1646e-02, -4.9060e-02,  3.4876e-02, -5.5494e-02, -5.6008e-02, -8.7335e-02, -7.0664e-02, -5.2432e-02,\n",
       "                       6.4677e-02,  4.4424e-02, -8.6658e-02, -8.1324e-02, -2.0023e-02,  5.7159e-02,  7.9289e-02,  8.8343e-02,\n",
       "                      -6.7977e-02, -1.7078e-02, -3.8186e-02,  4.4474e-02,  1.6891e-02, -8.5191e-03,  5.4869e-02, -7.5447e-02,\n",
       "                      -6.3755e-02,  7.9172e-02,  3.1717e-02,  1.5042e-02,  8.4010e-02, -3.2771e-02,  4.8325e-02, -6.4216e-03,\n",
       "                      -5.0842e-02, -3.1447e-02, -6.4737e-02, -6.4296e-02, -6.3796e-02,  2.1911e-02,  3.3993e-02, -8.7058e-02,\n",
       "                      -7.0215e-02,  6.4555e-02, -4.8956e-02,  6.6353e-02,  8.8407e-03, -6.5001e-02, -7.0726e-02, -2.4737e-02,\n",
       "                      -7.4416e-02, -8.9231e-02, -2.2937e-02,  3.6716e-02,  4.5244e-02,  6.3385e-02,  2.6265e-02,  1.1033e-02,\n",
       "                       5.3989e-02, -8.8849e-02, -8.8454e-02, -3.4999e-02,  6.3259e-02,  8.4146e-02,  1.5851e-02, -2.3992e-02,\n",
       "                       4.2129e-02, -8.0695e-02,  6.6961e-02, -7.2223e-02, -8.3022e-02,  4.6136e-02, -8.3059e-02, -6.4371e-02,\n",
       "                       8.0593e-02, -6.1140e-02,  7.7889e-02, -3.9653e-02, -1.1520e-02, -8.1838e-02,  6.7498e-02, -3.0454e-02,\n",
       "                      -3.4712e-02,  1.4264e-02,  4.6016e-02, -2.9421e-02, -3.0059e-02, -5.6736e-02, -5.2008e-02,  4.8574e-02,\n",
       "                       7.1771e-02, -6.0595e-02, -8.5497e-02, -5.6790e-02,  3.2661e-02,  4.9795e-02,  2.4619e-03, -8.6940e-02,\n",
       "                       6.4683e-02,  6.3108e-02, -2.5636e-03,  1.2487e-02,  8.8669e-02,  3.3468e-02,  1.8653e-02, -2.9251e-02,\n",
       "                       8.1003e-02,  8.4634e-02,  7.1036e-02, -5.0469e-03,  5.4200e-02,  3.3303e-02, -5.5225e-02, -2.7687e-02,\n",
       "                       2.3876e-02,  5.8315e-03,  8.5467e-02,  4.8198e-02, -6.6153e-02, -3.2147e-02, -6.8630e-02,  5.2691e-02,\n",
       "                       4.3748e-02,  3.7541e-02,  1.6044e-03,  1.2666e-02, -2.5751e-02,  1.9720e-02,  4.2551e-02,  7.0788e-02,\n",
       "                       7.4980e-03,  7.2490e-02,  7.1732e-02, -5.6586e-02, -8.2060e-02, -7.1679e-03,  6.5310e-02, -1.7482e-02,\n",
       "                      -5.5480e-02, -5.5920e-02,  4.1788e-02,  4.8798e-02,  4.0988e-02, -8.9312e-02, -5.3199e-03,  3.4246e-02,\n",
       "                      -5.3345e-02])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-3.1617e-02, -4.4832e-02, -2.6461e-02,  ..., -9.7102e-04, -3.3935e-02, -2.0084e-02],\n",
       "                      [ 3.8914e-02,  2.3153e-02, -1.2970e-02,  ..., -3.4943e-02, -1.0476e-05,  2.0020e-02],\n",
       "                      [ 9.1128e-03,  2.8599e-02, -1.6619e-02,  ..., -1.5101e-02,  3.7894e-02,  3.2047e-02],\n",
       "                      ...,\n",
       "                      [-5.8205e-03,  4.7530e-02, -2.9464e-02,  ..., -1.1386e-02, -4.2660e-02, -4.8713e-02],\n",
       "                      [ 1.3176e-02,  7.8945e-03,  2.7938e-02,  ..., -1.0724e-02, -5.3230e-03,  3.6068e-02],\n",
       "                      [ 1.0897e-02,  2.0537e-02, -5.7741e-03,  ...,  4.4481e-02, -1.1060e-02, -1.3046e-02]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0347, -0.0190, -0.0121, -0.0270, -0.0214,  0.0107,  0.0458, -0.0452,  0.0007, -0.0065]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-wot",
   "language": "python",
   "name": "nas-wot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
